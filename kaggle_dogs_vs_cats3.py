# -*- coding: utf-8 -*-
"""kaggle Dogs vs Cats3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SujMswr4S65n0KyNwqD042irpNSNQ3Gu
"""

# 1. 데이터 준비 및 전처리
# Kaggle API를 사용하여 데이터 다운로드 및 압축 해제

# !pip install -q kaggle

import os
from zipfile import ZipFile
from sklearn.model_selection import train_test_split
import shutil

# Kaggle API 키 업로드 (개인 키 필요)
# 사용자는 Kaggle API 키 파일을 직접 업로드해야 합니다.
# 업로드된 kaggle.json 파일은 API를 통한 데이터 다운로드에 필요합니다.

from google.colab import files
files.upload()

# Kaggle API 설정
# kaggle.json 파일을 적절한 위치로 이동시키고, 접근 권한을 변경하여 안전하게 사용하도록 설정합니다.
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# 데이터셋 다운로드 (Dogs vs Cats)
# Kaggle API를 통해 데이터를 다운로드하여 train.zip과 test1.zip 파일을 얻습니다.
!kaggle competitions download -c dogs-vs-cats

# /content/data 를 강제로 삭제하기
# import shutil
# shutil.rmtree('/content/data')

# 압축 해제 (dogs-vs-cats.zip)
# 먼저 'dogs-vs-cats.zip' 파일을 해제하여 'train.zip'과 'test1.zip' 파일을 얻습니다.
with ZipFile('dogs-vs-cats.zip', 'r') as zip_ref:
    zip_ref.extractall('data')

# 'train.zip' 및 'test1.zip' 압축 해제
# 각각의 압축 파일을 해제하되, 중첩된 폴더 없이 첫 번째 폴더에 바로 압축을 해제합니다.
with ZipFile('data/train.zip', 'r') as zip_ref:
    zip_ref.extractall('data/train')

with ZipFile('data/test1.zip', 'r') as zip_ref:
    zip_ref.extractall('data/test')

# 만약 압축 해제 과정에서 폴더 구조가 중첩된 경우, 폴더를 재구성
# 'data/train/train/' 구조로 압축이 풀렸다면 아래 코드로 중첩된 폴더를 제거
if os.path.exists('data/train/train'):
    for file in os.listdir('data/train/train'):
        shutil.move(os.path.join('data/train/train', file), 'data/train')
    shutil.rmtree('data/train/train')  # 중첩된 빈 폴더 삭제

# 'data/test/test1/' 구조로 압축이 풀렸다면 아래 코드로 중첩된 폴더를 제거
if os.path.exists('data/test/test1'):
    for file in os.listdir('data/test/test1'):
        shutil.move(os.path.join('data/test/test1', file), 'data/test')
    shutil.rmtree('data/test/test1')  # 중첩된 빈 폴더 삭제

# 데이터 분류 및 폴더 구조 설정
# train.zip에서 얻은 데이터는 이름에 'dog' 또는 'cat'이 포함되어 있습니다.
# 이미지 이름을 기준으로 개와 고양이 폴더로 분류하여 저장합니다.
train_dir = 'data/train'
os.makedirs(train_dir + '/dogs', exist_ok=True)
os.makedirs(train_dir + '/cats', exist_ok=True)

# 데이터 정리 (개와 고양이 분류)
# 각 파일 이름에 'dog' 또는 'cat'이 포함되어 있는지를 확인하여 해당 폴더로 이동시킵니다.
for file in os.listdir(train_dir):
    if 'dog' in file:
        shutil.move(os.path.join(train_dir, file), train_dir + '/dogs')
    elif 'cat' in file:
        shutil.move(os.path.join(train_dir, file), train_dir + '/cats')

# 이미지 경로 설정
# 각 클래스의 이미지 파일 목록을 불러옵니다.
dog_images = os.listdir(train_dir + '/dogs')
cat_images = os.listdir(train_dir + '/cats')

# 훈련 데이터 및 검증 데이터 분할
# 각각 개 2000장, 고양이 2000장만 사용
dog_train_full, dog_val_full = train_test_split(dog_images, train_size=2000, random_state=42)
cat_train_full, cat_val_full = train_test_split(cat_images, train_size=2000, random_state=42)

# 훈련 데이터 및 검증 데이터 분할 (훈련 1500장, 검증 500장)
dog_train, dog_val = train_test_split(dog_train_full, train_size=1500, random_state=42)
cat_train, cat_val = train_test_split(cat_train_full, train_size=1500, random_state=42)

#dog_train, dog_val, cat_train, cat_val 개수 확인하기
print(len(dog_train), len(dog_val), len(cat_train), len(cat_val))

# 훈련 및 검증 데이터 폴더 생성
train_split_dir = 'data/train_split'
val_split_dir = 'data/val_split'
os.makedirs(train_split_dir + '/dogs', exist_ok=True)
os.makedirs(train_split_dir + '/cats', exist_ok=True)
os.makedirs(val_split_dir + '/dogs', exist_ok=True)
os.makedirs(val_split_dir + '/cats', exist_ok=True)

# 훈련 데이터 복사
for file in dog_train:
    shutil.copy(os.path.join(train_dir + '/dogs', file), train_split_dir + '/dogs')
for file in cat_train:
    shutil.copy(os.path.join(train_dir + '/cats', file), train_split_dir + '/cats')

# 검증 데이터 복사
for file in dog_val:
    shutil.copy(os.path.join(train_dir + '/dogs', file), val_split_dir + '/dogs')
for file in cat_val:
    shutil.copy(os.path.join(train_dir + '/cats', file), val_split_dir + '/cats')

# 2. 데이터 전처리 및 증강
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# 훈련 데이터 변환 (이미지 크기 조정, 랜덤 수평 뒤집기, 랜덤 크롭)
train_transforms = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(224),
    transforms.ToTensor()
])

# 검증 데이터 변환 (이미지 크기 조정만 수행)
val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# ImageFolder로 데이터셋 로드
train_data = datasets.ImageFolder(train_split_dir, transform=train_transforms)
val_data = datasets.ImageFolder(val_split_dir, transform=val_transforms)

# DataLoader를 통해 배치 단위로 데이터 불러오기
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32, shuffle=False)

# 3. 모델 정의 및 수정
import torch
import torch.nn as nn
import torchvision.models as models

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#device 출력하기
print(device)

# ResNet50 모델 로드 (pretrained=True)
model = models.resnet50(pretrained=True)

# 분류기 레이어 변경 (2개 클래스: 개, 고양이)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 2)

model.to(device)

# 4. 학습 설정 및 진행
import torch.optim as optim
from tqdm import tqdm

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 10  # 학습 에포크 수

train_loss, val_loss = [], []
train_acc, val_acc = [], []

for epoch in range(num_epochs):
    model.train()
    running_loss, correct = 0.0, 0
    total = 0

    with tqdm(train_loader, unit="batch") as tepoch:
        for inputs, labels in tepoch:
            tepoch.set_description(f"Epoch {epoch + 1}")

            inputs, labels = inputs.to(device), labels.to(device)

            # Forward + Backward + Optimize
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # 손실 및 정확도 추적
            running_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)

            tepoch.set_postfix(loss=loss.item())

    epoch_loss = running_loss / total
    epoch_acc = correct / total

    train_loss.append(epoch_loss)
    train_acc.append(epoch_acc)

    # 검증 단계
    model.eval()
    running_loss, correct = 0.0, 0
    total = 0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)

            running_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)

    val_loss.append(running_loss / total)
    val_acc.append(correct / total)

    print(f'Epoch {epoch + 1}, Train Loss: {epoch_loss}, Train Acc: {epoch_acc}, Val Loss: {val_loss[-1]}, Val Acc: {val_acc[-1]}')

# 5. 테스트 및 추론 단계
import random
import matplotlib.pyplot as plt
from PIL import Image

# 테스트 데이터에서 30장 무작위 선택
test_dir = 'data/test'
test_images = random.sample(os.listdir(test_dir), 30)

# # 디버깅: 이미지 경로 출력 및 확인
# print("Selected test images:")
# for img_file in test_images:
#     print(os.path.join(test_dir, img_file))

# # 테스트 결과 시각화
# fig, axes = plt.subplots(5, 6, figsize=(12, 10))

# for i, img_file in enumerate(test_images):
#     img_path = os.path.join(test_dir, img_file)
#     try:
#         # 이미지 열기
#         img = Image.open(img_path).convert('RGB')

#         # 이미지 표시
#         ax = axes[i // 6, i % 6]
#         ax.imshow(img)
#         ax.axis('off')

#     except Exception as e:
#         # 예외 발생 시 출력
#         print(f"Error loading image {img_path}: {e}")

# plt.show()

# 테스트 변환 (이미지 크기 조정 및 텐서 변환만 수행)
test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# 테스트 결과 시각화
fig, axes = plt.subplots(5, 6, figsize=(12, 10))

model.eval()  # 모델을 평가 모드로 전환
with torch.no_grad():  # 추론 시에는 가중치 업데이트가 필요 없으므로 no_grad 사용
    for i, img_file in enumerate(test_images):
        # 이미지 로드 및 전처리
        img_path = os.path.join(test_dir, img_file)
        img = Image.open(img_path).convert('RGB')
        input_tensor = test_transforms(img).unsqueeze(0).to(device)

        # 모델을 통한 예측 수행
        output = model(input_tensor)
        _, pred = torch.max(output, 1)

        # 예측 결과에 따라 레이블 설정 (0: Dog, 1: Cat)
        label = 'Cat' if pred.item() == 0 else 'Dog'

        # 이미지와 예측 레이블 시각화
        ax = axes[i // 6, i % 6]
        ax.imshow(img)
        ax.set_title(label)
        ax.axis('off')

# 레이아웃 조정 및 플롯 표시
plt.tight_layout()
plt.show()

# 6. 학습 결과 시각화
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Train Loss')
plt.plot(val_loss, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_acc, label='Train Accuracy')
plt.plot(val_acc, label='Val Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()

plt.show()